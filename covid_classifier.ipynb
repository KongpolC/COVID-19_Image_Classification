{"cells":[{"cell_type":"code","metadata":{"id":"Z2PVBc7gMgaH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593405696847,"user_tz":-420,"elapsed":1773,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}},"outputId":"10fc8c70-3554-401b-998b-ef11a70bb0dd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pk65muHJz31h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593413917676,"user_tz":-420,"elapsed":1667,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}},"outputId":"19de8bb1-cf17-4e0c-b241-6a8635951528"},"source":["%cd /content/drive/My Drive/covid_image_classifier_extra_data"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/covid_image_classifier_extra_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7H6He3Pdu3wW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593413926540,"user_tz":-420,"elapsed":9925,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16, ResNet50V2, DenseNet121\n","from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense, Input, BatchNormalization, Activation\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import os\n","from tqdm import tqdm\n","from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, f1_score, precision_score, recall_score, classification_report\n","from datetime import datetime\n","import pickle as pkl\n","\n","tf.random.set_seed(51)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_7tOAS_yRQzX","colab_type":"text"},"source":["# Load and preprocess data"]},{"cell_type":"code","metadata":{"id":"x0QxyCmoryjz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593413926542,"user_tz":-420,"elapsed":4220,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["def to_one_hot(y):\n","  if y == 'covid':\n","    return np.array([1, 0, 0])\n","  elif y == 'normal':\n","    return np.array([0, 1, 0])\n","  elif y == 'pneumonia':\n","    return np.array([0, 0, 1])\n","  else:\n","    raise ValueError(y + ' does not belong to any class')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"t5bUm-csAq96","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593414000778,"user_tz":-420,"elapsed":1771,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["def load_from_path(path):\n","\n","  # Load and preprocess train data\n","  data = []\n","  labels = []\n","\n","  for folder in os.listdir(path):\n","    for img in tqdm(os.listdir(os.path.join(path, folder)), position=0, leave=True):\n","      try:\n","        # read, convert channels, and resize images\n","        image = cv2.imread(os.path.join(path, folder, img))\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        image = cv2.resize(image, (224, 224))\n","\n","        # Extract labels\n","        label = folder\n","\n","        # Append to lists\n","        data.append(image)\n","        labels.append(label)\n","      except:\n","        print('\\n', folder, img)\n","\n","  # Convert to numpy array and normalize images\n","  x = np.array(data)/255.\n","  y = np.array(labels)\n","  print('Shape of X = %s\\nShape of y = %s' % (str(x.shape), str(y.shape)))\n","\n","  # convert y to one-hot\n","  y_one_hot = np.array([to_one_hot(lab) for lab in y])\n","  print('Shape of y(onehot) = %s' % str(y_one_hot.shape))\n","\n","  return x, y, y_one_hot"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"IttouQtmEpwL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593415815868,"user_tz":-420,"elapsed":1822,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["def save_as_pickle(data, filename):\n","  if filename[-4:] != '.pkl':\n","    filename = filename + '.pkl'\n","    print(filename)\n","\n","  with open(filename, 'wb') as file:\n","    pkl.dump(data, file)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"fYugiuNiGBQt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593413939341,"user_tz":-420,"elapsed":1675,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["def load_pickle(filename):\n","  if filename[-4:] != '.pkl':\n","    filename = filename + '.pkl'\n","\n","  with open(filename, 'rb') as file:\n","    data = pkl.load(file)\n","\n","  return data"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjyOlUfMHrjp","colab_type":"code","colab":{}},"source":["# Load train and validation datasets\n","x_train, y_train, y_train_one_hot = load_from_path('data/train')\n","x_val, y_val, y_val_one_hot = load_from_path('data/test')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uuhkZ5CSztz-","colab_type":"code","colab":{}},"source":["# In case x_train exceeds 4 GB\n","x_train_1 = x_train[:int(x_train.shape[0]/2),:,:,:]\n","x_train_2 = x_train[int(x_train.shape[0]/2):,:,:,:]\n","print(x_train_1.shape, x_train_2.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"huYsMx7uIUjL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593415821405,"user_tz":-420,"elapsed":4588,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["# Save as pickles\n","save_as_pickle(x_train_1, 'x_train_1.pkl')\n","save_as_pickle(x_train_2, 'x_train_2.pkl')\n","save_as_pickle(y_train, 'y_train.pkl')\n","save_as_pickle(y_train_one_hot, 'y_train_one_hot.pkl')\n","\n","save_as_pickle(x_val, 'x_val.pkl')\n","save_as_pickle(y_val, 'y_val.pkl')\n","save_as_pickle(y_val_one_hot, 'y_val_one_hot.pkl')"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_dBGDk1IxRA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593413959308,"user_tz":-420,"elapsed":19485,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["# Load pickles\n","x_train_1 = load_pickle('x_train_1.pkl')\n","x_train_2 = load_pickle('x_train_2.pkl')\n","y_train = load_pickle('y_train.pkl')\n","y_train_one_hot = load_pickle('y_train_one_hot.pkl')\n","\n","x_val = load_pickle('x_val.pkl')\n","y_val = load_pickle('y_val.pkl')\n","y_val_one_hot = load_pickle('y_val_one_hot.pkl')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HrlPIxc26Va","colab_type":"code","colab":{}},"source":["# Combine x_train_1 and x_train_2\n","x_train = np.concatenate((x_train_1, x_train_2), axis=0)\n","print(x_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTuymGxO5Xj2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593408740806,"user_tz":-420,"elapsed":145604,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["# Overwrite x_train_1 and x_train_2 with 0 to clear memory\n","x_train_1 = 0\n","x_train_2 = 0"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e4KLopKoSMmW","colab_type":"text"},"source":["# Model\n","- VGG 16\n","- ResNet50V2\n","- DenseNet121"]},{"cell_type":"code","metadata":{"id":"xmP0mVC4JnlR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593408740809,"user_tz":-420,"elapsed":132609,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["def create_pretrained_model(model_name='resnetv2'):\n","  \n","  if model_name == 'resnetv2':\n","    return ResNet50V2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","  elif model_name == 'densenet121':\n","    return DenseNet121(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","  elif model_name == 'vgg16':\n","    return VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","  else:\n","    raise ValueError('Please specify model_name [\"resnetv2\", \"densenet121\", \"vgg16\"]')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVNLrmPdLS2M","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593402830967,"user_tz":-420,"elapsed":108236,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["def create_model(model_name):\n","  '''\n","  Creates model for transfer learning from pretrained model.\n","\n","  Arguments:\n","  model_name -- Name of pretrained models which include \"resnetv2\", \"densenet121\", \"vgg16\".\n","\n","  Returns:\n","  model -- a model instance in Keras for transfer learning.\n","  '''\n","\n","  # Load pretrained model and freeze it\n","  pretrained_model = create_pretrained_model(model_name)\n","  pretrained_model.trainable = False\n","\n","  # construct the head of the model that will be placed on top of the the base model\n","  x = GlobalAveragePooling2D()(pretrained_model.output)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.3)(x)\n","\n","  x = Dense(256)(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.4)(x)\n","  x = Dense(3, activation=\"softmax\")(x)\n","\n","  # place the head FC model on top of the base model (this will become the actual model we will train)\n","  model = Model(inputs=pretrained_model.input, outputs=x)\n","  print(model.summary())\n","\n","  return model"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"RcOU0ALpRVnv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593408755068,"user_tz":-420,"elapsed":138987,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}},"outputId":"75784133-98d4-43c3-d847-6233c61eed46"},"source":["model = create_model('resnetv2')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n","                                                                 conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d[0][0]              \n","                                                                 conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n","                                                                 conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_1[0][0]            \n","                                                                 conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n","                                                                 conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_2[0][0]            \n","                                                                 conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n","                                                                 conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 2048)         0           post_relu[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 2048)         8192        global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 2048)         0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 2048)         0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 256)          524544      dropout[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 256)          1024        dense[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 256)          0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 256)          0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 3)            771         dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 24,099,331\n","Trainable params: 529,923\n","Non-trainable params: 23,569,408\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OZUUX_cPNGpm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593364481492,"user_tz":-420,"elapsed":1085,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["def create_deep_model(model_name):\n","  '''\n","  Creates deep model for transfer learning from pretrained model.\n","  '''\n","\n","  # Load pretrained model and freeze it\n","  pretrained_model = create_pretrained_model(model_name)\n","  pretrained_model.trainable = False\n","\n","  # construct the head of the model that will be placed on top of the the base model\n","  x = GlobalAveragePooling2D()(pretrained_model.output)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.3)(x)\n","\n","  x = Dense(1024)(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.4)(x)\n","\n","  x = Dense(512)(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.4)(x)\n","\n","  x = Dense(256)(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.4)(x)\n","\n","  x = Dense(128)(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.4)(x)\n","\n","  x = Dense(64)(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","  x = Dropout(0.4)(x)\n","\n","  x = Dense(3, activation=\"softmax\")(x)\n","\n","  # place the head FC model on top of the base model (this will become the actual model we will train)\n","  model = Model(inputs=pretrained_model.input, outputs=x)\n","  print(model.summary())\n","\n","  return model"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0J3OF3e8Sv7X","colab_type":"text"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"2mwUxGhUS2RL","colab_type":"text"},"source":["- Set hyperparameters\n","- Compile\n","- Create callbacks to save only the best checkpoint\n","- Augment data\n","- Train"]},{"cell_type":"code","metadata":{"id":"pJzonlf6sHiS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":742},"outputId":"e9dd1723-7076-428c-8800-dd0271ef7dfa"},"source":["# Set hyperparameters\n","initial_lr = 3e-4\n","epochs = 25\n","batch_size = 16\n","decay_rate = 0.95\n","decay_step = 1\n","\n","# Compile model\n","opt = Adam(lr=initial_lr)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\", tf.keras.metrics.AUC()])\n","\n","# Save only the best checkpoint\n","time = datetime.now().strftime('_%H-%M-%S')\n","checkpoint_filepath_best = 'resnet50_batchnorm_first_checkpoints_best'+time+'/'\n","os.mkdir(checkpoint_filepath_best)\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath_best,\n","    save_weights_only=False,\n","    monitor='val_accuracy',# val_auc_4 val_accuracy\n","    mode='max',\n","    save_best_only=True)\n","\n","# Learning rate decay\n","lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch : initial_lr * (decay_rate**int(epoch / decay_step)))\n","\n","# Train the head of the network with image augmentation\n","train_generator = ImageDataGenerator(rotation_range=60, fill_mode=\"nearest\", horizontal_flip=True, vertical_flip=True)\n","\n","history = model.fit_generator(train_generator.flow(x_train, y_train_one_hot, batch_size=batch_size),\n","                              steps_per_epoch=len(x_train) // batch_size,\n","                              validation_data=(x_val, y_val_one_hot),\n","                              validation_steps=len(y_train_one_hot) // batch_size,\n","                              epochs=epochs,\n","                              callbacks=[model_checkpoint_callback, lr_schedule]) # class_weight={0:1, 1:1, 2:1}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-11-178b19992bdf>:34: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","Epoch 1/25\n","227/227 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.7482 - auc: 0.9000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 227 batches). You may need to use the repeat() function when building your dataset.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","INFO:tensorflow:Assets written to: resnet50_batchnorm_first_checkpoints_best_05-32-33/assets\n","227/227 [==============================] - 65s 288ms/step - loss: 0.6304 - accuracy: 0.7482 - auc: 0.9000 - val_loss: 0.4998 - val_accuracy: 0.7778 - val_auc: 0.9312 - lr: 3.0000e-04\n","Epoch 2/25\n","227/227 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.8192 - auc: 0.9442WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 227 batches). You may need to use the repeat() function when building your dataset.\n","INFO:tensorflow:Assets written to: resnet50_batchnorm_first_checkpoints_best_05-32-33/assets\n","227/227 [==============================] - 63s 280ms/step - loss: 0.4659 - accuracy: 0.8192 - auc: 0.9442 - val_loss: 0.4063 - val_accuracy: 0.8544 - val_auc: 0.9547 - lr: 2.8500e-04\n","Epoch 3/25\n","226/227 [============================>.] - ETA: 0s - loss: 0.4196 - accuracy: 0.8294 - auc: 0.9533WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 227 batches). You may need to use the repeat() function when building your dataset.\n","INFO:tensorflow:Assets written to: resnet50_batchnorm_first_checkpoints_best_05-32-33/assets\n","227/227 [==============================] - 63s 276ms/step - loss: 0.4201 - accuracy: 0.8292 - auc: 0.9532 - val_loss: 0.3663 - val_accuracy: 0.8602 - val_auc: 0.9629 - lr: 2.7075e-04\n","Epoch 4/25\n","227/227 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.8367 - auc: 0.9590WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 227 batches). You may need to use the repeat() function when building your dataset.\n","INFO:tensorflow:Assets written to: resnet50_batchnorm_first_checkpoints_best_05-32-33/assets\n","227/227 [==============================] - 61s 270ms/step - loss: 0.3922 - accuracy: 0.8367 - auc: 0.9590 - val_loss: 0.3538 - val_accuracy: 0.8697 - val_auc: 0.9659 - lr: 2.5721e-04\n","Epoch 5/25\n","227/227 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8430 - auc: 0.9612WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 227 batches). You may need to use the repeat() function when building your dataset.\n","227/227 [==============================] - 43s 192ms/step - loss: 0.3786 - accuracy: 0.8430 - auc: 0.9612 - val_loss: 0.3659 - val_accuracy: 0.8621 - val_auc: 0.9628 - lr: 2.4435e-04\n","Epoch 6/25\n","227/227 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8472 - auc: 0.9613WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 227 batches). You may need to use the repeat() function when building your dataset.\n","227/227 [==============================] - 43s 191ms/step - loss: 0.3786 - accuracy: 0.8472 - auc: 0.9613 - val_loss: 0.3638 - val_accuracy: 0.8544 - val_auc: 0.9634 - lr: 2.3213e-04\n","Epoch 7/25\n","227/227 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.8566 - auc: 0.9673WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 227 batches). You may need to use the repeat() function when building your dataset.\n","227/227 [==============================] - 43s 191ms/step - loss: 0.3454 - accuracy: 0.8566 - auc: 0.9673 - val_loss: 0.3783 - val_accuracy: 0.8467 - val_auc: 0.9619 - lr: 2.2053e-04\n","Epoch 8/25\n","227/227 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8527 - auc: 0.9648WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 227 batches). You may need to use the repeat() function when building your dataset.\n","227/227 [==============================] - 44s 193ms/step - loss: 0.3594 - accuracy: 0.8527 - auc: 0.9648 - val_loss: 0.4073 - val_accuracy: 0.8448 - val_auc: 0.9563 - lr: 2.0950e-04\n","Epoch 9/25\n","227/227 [==============================] - ETA: 0s - loss: 0.3402 - accuracy: 0.8643 - auc: 0.9683WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 227 batches). You may need to use the repeat() function when building your dataset.\n","227/227 [==============================] - 43s 192ms/step - loss: 0.3402 - accuracy: 0.8643 - auc: 0.9683 - val_loss: 0.3853 - val_accuracy: 0.8506 - val_auc: 0.9603 - lr: 1.9903e-04\n","Epoch 10/25\n","227/227 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.8712 - auc: 0.9713WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 227 batches). You may need to use the repeat() function when building your dataset.\n","227/227 [==============================] - 43s 190ms/step - loss: 0.3251 - accuracy: 0.8712 - auc: 0.9713 - val_loss: 0.3752 - val_accuracy: 0.8506 - val_auc: 0.9619 - lr: 1.8907e-04\n","Epoch 11/25\n","227/227 [==============================] - ETA: 0s - loss: 0.3306 - accuracy: 0.8618 - auc: 0.9700"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tjA5q7BTHj0v","colab_type":"code","colab":{}},"source":["# Plot and save training history\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(16, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.savefig(checkpoint_filepath_best+'training_graph.jpg')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"59IVIUHVTuV3","colab_type":"text"},"source":["# Benchmark\n","Focus mainly on F1-score"]},{"cell_type":"code","metadata":{"id":"HgTyROYueHXk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593413974366,"user_tz":-420,"elapsed":1596,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["def benchmark(model, save_path, x_val, y_val_one_hot):\n","  # Create prediction\n","  predictions = model.predict(x_val)\n","\n","  # Create Confusion Matrix\n","  cm = confusion_matrix(np.argmax(y_val_one_hot, axis=1), np.argmax(predictions, axis=1))\n","\n","  # Plot Confusion Matrix\n","  plot_confusion_matrix(cm, normalize=False, target_names=['covid', 'normal', 'pneumonia'], title=\"Confusion Matrix\", path=save_path)\n","\n","  # Print classification_report\n","  report = classification_report(np.argmax(y_val_one_hot, axis=1), np.argmax(predictions, axis=1), target_names=['covid','normal','pneumonia'], output_dict=True)\n","  avg_f1 = (report['covid']['f1-score'] + report['normal']['f1-score'] + report['pneumonia']['f1-score']) / 3\n","  avg_acc = report['accuracy']\n","  print(classification_report(np.argmax(y_val_one_hot, axis=1), np.argmax(predictions, axis=1), target_names=['covid','normal','pneumonia']))\n","  print('Average F1-Score =', avg_f1)\n","\n","  # Save avg_f1 and avg_acc to txt file\n","  with open(save_path+'benchmark.txt', 'w') as file:\n","    file.write('Average F1-Score: %.4f\\nAverage Accuracy: %.4f' % (avg_f1, avg_acc))\n","    file.write(str(report))\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"YA5mcgfGLVp_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593413974368,"user_tz":-420,"elapsed":1197,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}}},"source":["def plot_confusion_matrix(cm, target_names, path, title='Confusion matrix', cmap=None, normalize=True):\n","    \"\"\"\n","    given a sklearn confusion matrix (cm), make a nice plot\n","\n","    Arguments\n","    ---------\n","    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n","\n","    target_names: given classification classes such as [0, 1, 2]\n","                  the class names, for example: ['high', 'medium', 'low']\n","\n","    title:        the text to display at the top of the matrix\n","\n","    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n","                  see http://matplotlib.org/examples/color/colormaps_reference.html\n","                  plt.get_cmap('jet') or plt.cm.Blues\n","\n","    normalize:    If False, plot the raw numbers\n","                  If True, plot the proportions\n","\n","    Usage\n","    -----\n","    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n","                                                              # sklearn.metrics.confusion_matrix\n","                          normalize    = True,                # show proportions\n","                          target_names = y_labels_vals,       # list of names of the classes\n","                          title        = best_estimator_name) # title of graph\n","\n","    Citiation\n","    ---------\n","    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    import numpy as np\n","    import itertools\n","\n","    accuracy = np.trace(cm) / float(np.sum(cm))\n","    misclass = 1 - accuracy\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Blues')\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title, fontsize = 'xx-large')\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n","    plt.savefig(path+'confusion_matrix.png')\n","    plt.show()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"NbMxa1wqemGI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":652},"executionInfo":{"status":"ok","timestamp":1593416116847,"user_tz":-420,"elapsed":15703,"user":{"displayName":"Kongpol C","photoUrl":"","userId":"15775635515786837711"}},"outputId":"87a5d070-5c0a-4d11-c8eb-0534362c7ca2"},"source":["# Benchmark the model\n","benchmark(tf.keras.models.load_model(checkpoint_filepath_best), save_path='', x_val=x_val, y_val_one_hot=y_val_one_hot)"],"execution_count":35,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","       covid       0.96      0.95      0.96        80\n","      normal       0.95      0.90      0.93       235\n","   pneumonia       0.86      0.93      0.89       158\n","\n","    accuracy                           0.92       473\n","   macro avg       0.92      0.93      0.93       473\n","weighted avg       0.92      0.92      0.92       473\n","\n","Average F1-Score = 0.9251186853945429\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VYfaem06OAsd","colab_type":"text"},"source":["# Resources"]},{"cell_type":"markdown","metadata":{"id":"sASZj5tVODjF","colab_type":"text"},"source":["## - Train flow from directories\n","Super slow because it streams data from google drive. To solve this, get data from google drive onto this instances which also takes too much time."]},{"cell_type":"code","metadata":{"id":"JqYdcPTSDLzJ","colab_type":"code","colab":{}},"source":["train_image_generator = ImageDataGenerator(\n","                    rescale=1./255,\n","                    rotation_range=15,\n","                    # width_shift_range=.15,\n","                    # height_shift_range=.15,\n","                    #horizontal_flip=True,\n","                    #vertical_flip=True,\n","                    # zoom_range=0.5,\n","                    fill_mode='nearest' #'reflect'\n","                    )\n","\n","validation_image_generator = ImageDataGenerator(\n","                    rescale=1./255,\n","                    # rotation_range=45,\n","                    # horizontal_flip=True,\n","                    ) # Generator for our validation data\n","\n","# Set hyperparameter\n","batch_size = 16\n","epochs = 30\n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224\n","train_dir = 'data/train'\n","validation_dir = 'data/test'\n","\n","train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n","                                                           directory=train_dir,\n","                                                           shuffle=True,\n","                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                           class_mode='categorical',\n","                                                           color_mode=\"rgb\")\n","\n","val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n","                                                              directory=validation_dir,\n","                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                              class_mode='categorical',\n","                                                              color_mode=\"rgb\")\n","\n","# Set hyperparameters\n","initial_lr = 1e-3\n","decay_rate = 0.3\n","\n","# compile our model\n","opt = Adam(lr=initial_lr)#, decay=INIT_LR / EPOCHS)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\", tf.keras.metrics.AUC()])\n","\n","# Save only best checkpoints\n","time = datetime.now().strftime('_%H-%M-%S')\n","\n","checkpoint_filepath_best = 'resnet50_all_checkpoints_best'+time+'/'\n","os.mkdir(checkpoint_filepath_best)\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath_best,\n","    save_weights_only=False,\n","    monitor='val_accuracy',# val_auc_4 val_accuracy\n","    mode='max',\n","    save_best_only=True)\n","\n","# Learning rate decay\n","lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: initial_lr/(1+decay_rate*epoch))\n","\n","# Train\n","history = model.fit_generator(\n","    train_data_gen,\n","    steps_per_epoch=train_data_gen.samples // batch_size,\n","    epochs=epochs,\n","    validation_data=val_data_gen,\n","    validation_steps=val_data_gen.samples // batch_size,\n","    callbacks=[model_checkpoint_callback, lr_schedule]\n",")"],"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"covid_classifier.ipynb","provenance":[{"file_id":"1z7qe7EXrqfGa8RnVfKe0CCUQ96g5uIKI","timestamp":1593084701891}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}